{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gothic-engineer",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import collections\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Import the data set\n",
    "path = r'Path file'\n",
    "# For the electronic store data set\n",
    "df = pd.read_csv(path, index_col=None, header=0)\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-karma",
   "metadata": {},
   "source": [
    "# Customization of the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Edit the data set\n",
    "# Convert the data type of the date to \"datetime\"\n",
    "df['event_time']= pd.to_datetime(df['event_time'], infer_datetime_format=True).dt.tz_localize(None)\n",
    "# Convert the other data types\n",
    "df = df.astype({'event_type':'category', 'product_id':'category', 'category_id':'category', \"category_code\":'category', \"brand\": 'category', \"user_id\": 'category',\"user_session\":'category'})\n",
    "print(\"Converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-meaning",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################### Preprocessing\n",
    "df = df[df['user_session'].notna()]\n",
    "#################### Define a user session as all events that are recorded for one user (user id) in a timeframe without 30 minutes of no event (inactivity)\n",
    "# Create a new column \"session\" that contains all events of one user in a timeframe and ends after 30 minutes of no event (inactivity)\n",
    "df['session'] = (df.groupby('user_id')['event_time'].transform(lambda x: x.diff().gt('30Min').cumsum()))\n",
    "# Create a new user session id: \"user_session_id_new\"\n",
    "df[\"user_session_id_new\"] = df[\"user_id\"].astype(str)+df['session'].astype(str)\n",
    "df[\"user_session_id_new\"].nunique() \n",
    "df = df.astype({\"user_session_id_new\":'category'})\n",
    "print(\"Sessions were redefined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-excess",
   "metadata": {},
   "source": [
    "## Removal of sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### # Count the number of different event types per session\n",
    "sessionDictonaryNumberOfViews = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfCarts = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfPurchases = df[df[\"event_type\"]==\"purchase\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "\n",
    "# Remove all sessions that have no view event, but have cart events, purchase events, or cart and purchase events\n",
    "sessionsToRemove = {k:v for k,v in sessionDictonaryNumberOfViews.items() if v==0}\n",
    "df = df[~df.user_session_id_new.isin(sessionsToRemove.keys())]\n",
    "df['user_session_id_new'] = df.user_session_id_new.cat.remove_unused_categories()\n",
    "# Remove all sessions that have purchase events but no cart events\n",
    "# sessionsToRemove = {k:v for k,v in sessionDictonaryNumberOfCarts.items() if (v == 0 and sessionDictonaryNumberOfPurchases[k]>0)}\n",
    "# df = df[~df.user_session_id_new.isin(sessionsToRemove.keys())]\n",
    "\n",
    "########## Additional dataframes\n",
    "sessionViewDf = df[df[\"event_type\"]== \"view\"]\n",
    "sessionCartDf = df[df[\"event_type\"]== \"cart\"]\n",
    "sessionPurchaseDf = df[df[\"event_type\"]== \"purchase\"]\n",
    "sessionEntriesViewCart = sessionViewDf.append(sessionCartDf)\n",
    "sessionDictonaryNumberOfTotalEventsPerSession = sessionEntriesViewCart.groupby(\"user_session_id_new\").size()\n",
    "print(\"Sessions removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all sessions with less than two events\n",
    "#NumberOfEventsPerSession = df.user_session_id_new.value_counts()\n",
    "NumberOfEventsPerSession = df.groupby(\"user_session_id_new\").size()\n",
    "print(\"Number of remaining sessions:\", df[\"user_session_id_new\"].nunique())\n",
    "print(\"Length of df before removing sessions with less than two events:\",len(df))\n",
    "df=df[df.user_session_id_new.isin(sessionDictonaryNumberOfTotalEventsPerSession.index[sessionDictonaryNumberOfTotalEventsPerSession.gt(1)])]\n",
    "print(\"Length of df after removing sessions with less than two events:\",len(df))\n",
    "# Remove sessions with more than 100 events\n",
    "print(\"Length of df before removing sessions with more than threehundred events:\",len(df))\n",
    "df=df[df.user_session_id_new.isin(NumberOfEventsPerSession.index[NumberOfEventsPerSession.lt(101)])]\n",
    "print(\"Length of df after removing sessions with more than 100 events:\",len(df))\n",
    "# Remove unused categories of user_session_id_new\n",
    "df['user_session_id_new'] = df.user_session_id_new.cat.remove_unused_categories()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Further sessions removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-volume",
   "metadata": {},
   "source": [
    "## Update session number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-rider",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['session'] = (df.groupby('user_id')['event_time'].transform(lambda x: x.diff().gt('30Min').cumsum()))\n",
    "# Create a new user session id: \"user_session_id_new\"\n",
    "df[\"user_session_id_new\"] = df[\"user_id\"].astype(str)+df['session'].astype(str)\n",
    "df[\"user_session_id_new\"].nunique() \n",
    "df = df.astype({\"user_session_id_new\":'category', \"session\":'int'})\n",
    "print(\"Sessions updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-dylan",
   "metadata": {},
   "source": [
    "# Creation of new features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-electron",
   "metadata": {},
   "source": [
    "## Features for the time and for the product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for the day, month, weekDay, hour\n",
    "df[\"day\"] = df['event_time'].dt.day\n",
    "df[\"month\"] = df['event_time'].dt.month\n",
    "df[\"weekDay\"] = df['event_time'].dt.weekday\n",
    "df[\"hour\"] = df['event_time'].dt.hour\n",
    "# Create a variable that indicates whether it is a weekday or not (= a weekend day)\n",
    "df[\"weekDayOrNot\"] = df[\"weekDay\"]<5\n",
    "# Create the variable dayTime with 6 different categories\n",
    "df['dayTime'] = (df['event_time'].dt.hour % 24 + 4) // 4\n",
    "df['dayTime'].replace({1: 'Late Night',\n",
    "                      2: 'Early Morning',\n",
    "                      3: 'Morning',\n",
    "                      4: 'Noon',\n",
    "                      5: 'Evening',\n",
    "                      6: 'Night'}, inplace=True)\n",
    "# Create a new variable from \"category_code\" for the parent category / product type\n",
    "df['parentProductCategory'] = df['category_code'].str.split(\".\").str[0]\n",
    "# Create a new variable from \"category_code\" for the secondary category / product type\n",
    "df['secondaryProductCategory'] = df['category_code'].str.split(\".\").str[1]\n",
    "# Create a new variable from \"category_code\" for the third category / product type\n",
    "df['thirdProductCategory'] = df['category_code'].str.split(\".\").str[2]\n",
    "# Change the data types of the new created variables\n",
    "df = df.astype({'day':'category', 'month':'category',\"weekDay\": \"category\", \"hour\": \"category\",\"dayTime\": \"category\", \"parentProductCategory\": \"category\", 'secondaryProductCategory': \"category\",'thirdProductCategory':\"category\"})\n",
    "print(\"New variables created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-policy",
   "metadata": {},
   "source": [
    "## Replacement of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which columns there a missing values\n",
    "df.columns[df.isnull().any()]\n",
    "# Result: category_code', 'brand', 'parentProductCategory', 'secondaryProductCategory', 'thirdProductCategory'\n",
    "# # Replace all missing values of the column brand (with \"Unknown brand\") and of the category columns (with \"Unknown category\")\n",
    "df[\"brand\"] = np.where(df[\"brand\"].isnull(),\"Unknown brand\",df[\"brand\"])\n",
    "df[\"category_code\"] = np.where(df[\"category_code\"].isnull(),\"Unknown category\",df[\"category_code\"])\n",
    "df[\"parentProductCategory\"] = np.where(df[\"parentProductCategory\"].isnull(),\"Unknown category\",df[\"parentProductCategory\"])\n",
    "df[\"secondaryProductCategory\"] = np.where(df[\"secondaryProductCategory\"].isnull(),\"Unknown category\",df[\"secondaryProductCategory\"])\n",
    "df[\"thirdProductCategory\"] = np.where(df[\"thirdProductCategory\"].isnull(),\"Unknown category\",df[\"thirdProductCategory\"])\n",
    "print(\"Replacement finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-cooper",
   "metadata": {},
   "source": [
    "## Features regarding the time of the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Create new variables based on the length of the session\n",
    "# Calculate first and last timestamp of a session to calculate the \"sessionLength\"\n",
    "timeDiff = df.groupby(\"user_session_id_new\")['event_time'].agg(['min','max']).rename(columns={'min':'first','max':'last'})\n",
    "timeDiff[\"sessionLength\"] = timeDiff[\"last\"] - timeDiff[\"first\"]\n",
    "timeDiff = timeDiff.reset_index() \n",
    "timeDiff = timeDiff.sort_values(\"user_session_id_new\")\n",
    "print(\"Calculated the session length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the maximal time between two events of one session\n",
    "# Use only the values where there are no missing values in the column user session\n",
    "#dfTime = df[df['user_session'].notna()]\n",
    "dfTime = df.copy()\n",
    "dfTime['diff'] = dfTime.sort_values(['user_session_id_new','event_time']).groupby('user_session_id_new')['event_time'].diff()\n",
    "dfTime.loc[pd.isnull(dfTime['diff']), 'diff'] = pd.Timedelta(seconds=0)\n",
    "#maxTimeDiff contains the maximal time between two events of one session\n",
    "maxTimeDiff = dfTime.groupby('user_session_id_new')['diff'].max().to_dict()\n",
    "print(\"Calculated the maximal time between two events of one session\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-flush",
   "metadata": {},
   "source": [
    "## Calculation of unique views and unique carts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update\n",
    "sessionDictonaryNumberOfViews = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfCarts = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfPurchases = df[df[\"event_type\"]==\"purchase\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "# Calculate the total events of a session: \n",
    "sessionViewDf = df[df[\"event_type\"]== \"view\"]\n",
    "sessionCartDf = df[df[\"event_type\"]== \"cart\"]\n",
    "sessionEntriesViewCart = sessionViewDf.append(sessionCartDf)\n",
    "sessionDictonaryNumberOfTotalEventsPerSessionViewAndCart = sessionEntriesViewCart.groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfTotalEventsPerSession = df.groupby(\"user_session_id_new\").size().to_dict()\n",
    "# Group by user session id new and add all id's of products related to view, cart and purchase events to a dictonary (with duplicates)\n",
    "sessionDictonaryViewedProducts = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\")['product_id'].apply(list).to_dict() \n",
    "sessionDictonaryCartedProducts  = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\")['product_id'].apply(list).to_dict()\n",
    "sessionDictonaryPurchasedProducts = df[df[\"event_type\"]==\"purchase\"].groupby(\"user_session_id_new\")['product_id'].apply(list).to_dict()\n",
    "# Calculate unique views and carts\n",
    "numberOfUniqueViewsPerSession ={}\n",
    "numberOfUniqueCartsPerSession ={}\n",
    "#numberOfUniquePurchasesPerSession ={}\n",
    "\n",
    "for key, number in sessionDictonaryViewedProducts.items():\n",
    "    numberSet = set(sessionDictonaryViewedProducts[key])\n",
    "    numberOfUniqueViewsPerSession[key] = len(numberSet)\n",
    "    if sessionDictonaryNumberOfCarts[key]==0:\n",
    "        numberOfUniqueCartsPerSession[key] = 0\n",
    "\n",
    "for key, number in sessionDictonaryCartedProducts.items():\n",
    "    numberSet = set(sessionDictonaryCartedProducts[key])\n",
    "    numberOfUniqueCartsPerSession[key] = len(numberSet)\n",
    "# unique purchases\n",
    "#for key, number in sessionDictonaryPurchasedProducts.items():\n",
    "    #numberSet = set(sessionDictonaryPurchasedProducts[key])\n",
    "    #numberOfUniquePurchasesPerSession[key] = len(numberSet)\n",
    "print(\"Calculation finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-carter",
   "metadata": {},
   "source": [
    "## Calculation of the number of different viewed categories (first, second, third) and creation of the visitor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user session id new and add all id's of products related to view, cart and purchase events to a dictonary (with duplicates)\n",
    "sessionDictonaryViewedCategoriesFirstLevel = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\")['parentProductCategory'].apply(list).to_dict() \n",
    "sessionDictonaryViewedCategoriesSecondLevel = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\")['secondaryProductCategory'].apply(list).to_dict() \n",
    "sessionDictonaryViewedCategoriesThirdLevel = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\")['thirdProductCategory'].apply(list).to_dict() \n",
    "\n",
    "sessionDictonaryCartedCategoriesFirstLevel = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\")['parentProductCategory'].apply(list).to_dict() \n",
    "sessionDictonaryCartedCategoriesSecondLevel = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\")['secondaryProductCategory'].apply(list).to_dict() \n",
    "sessionDictonaryCartedCategoriesThirdLevel = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\")['thirdProductCategory'].apply(list).to_dict() \n",
    "\n",
    "# Calculate unique views and carts\n",
    "numberOfUniqueViewsPerSessionFirstLevel ={}\n",
    "numberOfUniqueViewsPerSessionSecondLevel ={}\n",
    "numberOfUniqueViewsPerSessionThirdLevel ={}\n",
    "\n",
    "numberOfUniqueCartsPerSessionFirstLevel ={}\n",
    "numberOfUniqueCartsPerSessionSecondLevel ={}\n",
    "numberOfUniqueCartsPerSessionThirdLevel ={}\n",
    "\n",
    "for key, number in sessionDictonaryViewedCategoriesFirstLevel.items():\n",
    "    #First level\n",
    "    numberSet = set(sessionDictonaryViewedCategoriesFirstLevel[key])\n",
    "    numberOfUniqueViewsPerSessionFirstLevel[key] = len(numberSet)\n",
    "    #Second level\n",
    "    numberSet = set(sessionDictonaryViewedCategoriesSecondLevel[key])\n",
    "    numberOfUniqueViewsPerSessionSecondLevel [key] = len(numberSet)\n",
    "    #Third level\n",
    "    numberSet = set(sessionDictonaryViewedCategoriesThirdLevel[key])\n",
    "    numberOfUniqueViewsPerSessionThirdLevel[key] = len(numberSet)\n",
    "    #Sessions without a cart\n",
    "    if sessionDictonaryNumberOfCarts[key]==0:\n",
    "        numberOfUniqueCartsPerSessionFirstLevel[key] = 0\n",
    "        numberOfUniqueCartsPerSessionSecondLevel[key] = 0\n",
    "        numberOfUniqueCartsPerSessionThirdLevel[key] = 0\n",
    "\n",
    "for key, number in sessionDictonaryCartedCategoriesFirstLevel.items():\n",
    "    #First level\n",
    "    numberSet = set(sessionDictonaryCartedCategoriesFirstLevel[key])\n",
    "    numberOfUniqueCartsPerSessionFirstLevel [key] = len(numberSet)\n",
    "    #Second level\n",
    "    numberSet = set(sessionDictonaryCartedCategoriesSecondLevel[key])\n",
    "    numberOfUniqueCartsPerSessionSecondLevel [key] = len(numberSet)\n",
    "    #Third level\n",
    "    numberSet = set(sessionDictonaryCartedCategoriesThirdLevel[key])\n",
    "    numberOfUniqueCartsPerSessionThirdLevel[key] = len(numberSet)\n",
    "        \n",
    "# Create a column visitor type (new visitor (true) or not (false))\n",
    "df[\"newVisitorOrNot\"] = df[\"session\"]== 0\n",
    "print(\"Calculation finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-google",
   "metadata": {},
   "source": [
    "## Calculation of total value of viewed and carted products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by user session id new and get the total value of views per session and calculate the average value of viewed items\n",
    "sessionDictonaryTotalValueOfViews = df[df[\"event_type\"]==\"view\"].groupby(\"user_session_id_new\")['price'].sum().to_dict()\n",
    "sessionDictonaryAverageValueOfViews = {}\n",
    "for key in sessionDictonaryTotalValueOfViews:\n",
    "    if (sessionDictonaryNumberOfViews[key]>0):\n",
    "        sessionDictonaryAverageValueOfViews[key]=sessionDictonaryTotalValueOfViews[key]/sessionDictonaryNumberOfViews[key]\n",
    "    else: sessionDictonaryAverageValueOfViews[key] = 0\n",
    "# Group by user session and get the total value of carts per session and calculate the average value of carted items\n",
    "sessionDictonaryTotalValueOfCarts = df[df[\"event_type\"]==\"cart\"].groupby(\"user_session_id_new\")['price'].sum().to_dict()\n",
    "sessionDictonaryAverageValueOfCarts = {}\n",
    "for key in sessionDictonaryTotalValueOfCarts:\n",
    "    if (sessionDictonaryNumberOfCarts[key]>0):\n",
    "        sessionDictonaryAverageValueOfCarts[key]=sessionDictonaryTotalValueOfCarts[key]/sessionDictonaryNumberOfCarts[key]\n",
    "    else: \n",
    "        sessionDictonaryAverageValueOfCarts[key] = 0\n",
    "for key, number in sessionDictonaryViewedProducts.items():\n",
    "    if key not in sessionDictonaryTotalValueOfCarts:\n",
    "        sessionDictonaryTotalValueOfCarts[key]= 0\n",
    "        sessionDictonaryAverageValueOfCarts[key] = 0\n",
    "print(\"Calculation finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-schema",
   "metadata": {},
   "source": [
    "# Creation of a dataframe for sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that has features on session level\n",
    "sessionDf = df.copy(deep=True)\n",
    "sessionDf = sessionDf.drop_duplicates(subset='user_session_id_new', keep=\"first\")\n",
    "sessionDf = sessionDf.drop(['event_type','product_id','category_id',\n",
    " 'category_code',\n",
    " 'brand',\n",
    " 'price',\n",
    " 'user_session',\n",
    " 'session',\n",
    " 'parentProductCategory',\n",
    " 'secondaryProductCategory',\n",
    " 'thirdProductCategory'], axis=1)\n",
    "\n",
    "sessionDf = sessionDf.sort_values(\"user_session_id_new\")\n",
    "sessionDf[\"number_of_views\"] = pd.DataFrame(sessionDictonaryNumberOfViews.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_carts\"] = pd.DataFrame(sessionDictonaryNumberOfCarts.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_purchases\"] = pd.DataFrame(sessionDictonaryNumberOfPurchases.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_total_events_per_session_view_cart\"] = pd.DataFrame(sessionDictonaryNumberOfTotalEventsPerSessionViewAndCart.items()).sort_values(0)[1].values\n",
    "sessionDf[\"total_value_of_views\"] = pd.DataFrame(sessionDictonaryTotalValueOfViews.items()).sort_values(0)[1].values\n",
    "sessionDf[\"total_value_of_carts\"] = pd.DataFrame(sessionDictonaryTotalValueOfCarts.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_views\"] = pd.DataFrame(numberOfUniqueViewsPerSession.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_carts\"] = pd.DataFrame(numberOfUniqueCartsPerSession.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_views_first_category_level\"] = pd.DataFrame(numberOfUniqueViewsPerSessionFirstLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_views_second_category_level\"] = pd.DataFrame(numberOfUniqueViewsPerSessionSecondLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_views_third_category_level\"] = pd.DataFrame(numberOfUniqueViewsPerSessionThirdLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_carts_first_category_level\"] = pd.DataFrame(numberOfUniqueCartsPerSessionFirstLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_carts_second_category_level\"] = pd.DataFrame(numberOfUniqueCartsPerSessionSecondLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"number_of_unique_carts_third_category_level\"] = pd.DataFrame(numberOfUniqueCartsPerSessionThirdLevel.items()).sort_values(0)[1].values\n",
    "sessionDf[\"session_length\"] = timeDiff[\"sessionLength\"].values\n",
    "sessionDf[\"max_time_between_two_events\"] = pd.DataFrame(maxTimeDiff.items()).sort_values(0)[1].values\n",
    "sessionDf[\"average_value_of_views\"]= pd.DataFrame(sessionDictonaryAverageValueOfViews.items()).sort_values(0)[1].values\n",
    "sessionDf[\"average_value_of_carts\"] = pd.DataFrame(sessionDictonaryAverageValueOfCarts.items()).sort_values(0)[1].values\n",
    "# Create a column that indicates whether it is a \"purchase session\" or not\n",
    "sessionDf[\"PurchaseSession\"] = np.multiply(sessionDf[\"number_of_purchases\"]>0,1)\n",
    "print(\"Dataframe finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perfect-significance",
   "metadata": {},
   "source": [
    "## Selection of a subset of sessions from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sessions that dont have a view event as their first session event\n",
    "dfCopy = df.copy(deep=True).sort_values(by='event_time')\n",
    "sessionsFirst = dfCopy.groupby(\"user_session_id_new\").first().reset_index()\n",
    "sessionsFirstView = sessionsFirst[sessionsFirst.event_type == \"view\"]\n",
    "sessionDfCopy = sessionDf.copy(deep=True)\n",
    "sessionDfCopy = sessionDfCopy[sessionDfCopy.user_session_id_new.isin(sessionsFirstView.user_session_id_new)]\n",
    "sessionDfCopy['user_session_id_new'] = sessionDfCopy.user_session_id_new.cat.remove_unused_categories()\n",
    "\n",
    "X_session = sessionDfCopy.drop(\"PurchaseSession\",axis=1)\n",
    "y_session = sessionDfCopy.PurchaseSession\n",
    "\n",
    "# Also remove the sessions without view event from the event dataframe\n",
    "Xy_event = df.copy(deep=True)\n",
    "Xy_event = Xy_event[Xy_event.user_session_id_new.isin(sessionsFirstView.user_session_id_new)]\n",
    "Xy_event['user_session_id_new']= Xy_event.user_session_id_new.cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a label to every row of the event dataframe (every event) (purchase session or not)\n",
    "Xy_event[\"PurchaseSession\"] = Xy_event.user_session_id_new.copy(deep=True)\n",
    "Xy_event[\"PurchaseSession\"] = Xy_event[\"PurchaseSession\"].map(sessionDictonaryNumberOfPurchases)\n",
    "Xy_event.loc[Xy_event[\"PurchaseSession\"] > 0, 'PurchaseSession'] = 1\n",
    "Xy_event.loc[Xy_event[\"PurchaseSession\"] == 0, 'PurchaseSession'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training and test set\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_session, y_session, test_size=50000, train_size=50000, random_state=42, stratify = y_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-timer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate training and test set of the session and event dataframe\n",
    "# session df\n",
    "sessionDfCopy.loc[sessionDfCopy.user_session_id_new.isin(X_train_s.user_session_id_new), [\"set\"]] = \"train\"\n",
    "sessionDfCopy.loc[sessionDfCopy.user_session_id_new.isin(X_test_s.user_session_id_new), [\"set\"]] = \"test\"\n",
    "\n",
    "# event df\n",
    "Xy_event.loc[Xy_event.user_session_id_new.isin(X_train_s.user_session_id_new), [\"set\"]] = \"train\"\n",
    "Xy_event.loc[Xy_event.user_session_id_new.isin(X_test_s.user_session_id_new), [\"set\"]] = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-mattress",
   "metadata": {},
   "source": [
    "## Saving the processed data sets as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "from pathlib import Path\n",
    "# Save the session dataframe and the event dataframe as csv file\n",
    "# Save final event dataframe\n",
    "filepath = Path('File path')\n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "Xy_event.to_csv(filepath, encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "# Save final session dataframe\n",
    "filepath = Path('File path') \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "sessionDfCopy.to_csv(filepath, encoding='utf-8', index=False)\n",
    "print(\"Files saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-incidence",
   "metadata": {},
   "source": [
    "## Calculation of statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only calculate the statistics for the train data set\n",
    "Xy_event_train = Xy_event.loc[Xy_event['set'] == \"train\"]\n",
    "sessionDfCopy_train = sessionDfCopy.loc[sessionDfCopy['set'] == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"---------------------------------------------\")\n",
    "\"\"\"**Calculate some statistics**\"\"\"\n",
    "# First and last date \n",
    "print(\"First date:\", min(Xy_event_train[\"event_time\"]),\"Last date:\", max(Xy_event_train[\"event_time\"]))\n",
    "# Number of total events\n",
    "print(\"Number of total events:\", len(Xy_event_train))\n",
    "# Number of sessions\n",
    "print(\"Total Number of sessions:\", Xy_event_train[\"user_session_id_new\"].nunique(), len(sessionDfCopy_train))\n",
    "# Number of users\n",
    "print(\"Number of users:\", Xy_event_train[\"user_id\"].nunique())\n",
    "# Number of sessions with only one event\n",
    "sessionDictonaryNumberOfTotalEventsPerSession = Xy_event_train.groupby(\"user_session_id_new\").size().to_dict()\n",
    "sessionDictonaryNumberOfTotalEventsPerSession = {key:val for key, val in sessionDictonaryNumberOfTotalEventsPerSession.items() if val != 0}\n",
    "# Only use the sessions with at least 2 events: len(allSessionsWithAtLeast4Events):\n",
    "allSessionsWith1Event = { k:v for k, v in sessionDictonaryNumberOfTotalEventsPerSession.items() if v == 1 }\n",
    "print(\"Sessions with only one event:\",len(allSessionsWith1Event))\n",
    "print(\"Sessions with only one event in percent:\", len(allSessionsWith1Event)/len(sessionDictonaryNumberOfTotalEventsPerSession)*100, \"%\")\n",
    "# Average number of clicks per session:\n",
    "print(\"Average number of clicks per session:\",sum(sessionDictonaryNumberOfTotalEventsPerSession.values()) / float(len(sessionDictonaryNumberOfTotalEventsPerSession)))\n",
    "# Percentage of purchase sessions (session with at least one purchase)\n",
    "sessionDictonaryPurchaseSession = Xy_event_train[Xy_event_train[\"event_type\"]==\"purchase\"].groupby(\"user_session_id_new\").size().to_dict()\n",
    "numberOfPurchaseSessions = len({ k:v for k, v in sessionDictonaryPurchaseSession.items() if v > 0 })\n",
    "print(\"Number of purchase sessions:\",numberOfPurchaseSessions)\n",
    "print(\"Share of purchase sessions:\", numberOfPurchaseSessions/len(sessionDictonaryNumberOfTotalEventsPerSession)*100,\"%\")\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-scenario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-gallery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-contact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-train",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
